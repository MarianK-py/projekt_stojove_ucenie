{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 229,
   "id": "5a56229c-c55f-4e50-b282-6fc8f0ab0713",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.utils import shuffle\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation\n",
    "#import tensorflow_datasets as tfds\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn import svm, linear_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "id": "109d85a5-3d19-47a6-a12f-98f76f1b2f53",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"weather_data/weather_prediction_dataset.csv\")\n",
    "towns = {col.split(\"_\")[0] for col in data.columns[2:]}\n",
    "m = [min([i if c.lower() == c else 10 for i, c in enumerate(col.split(\"_\"))]) for col in data.columns]\n",
    "towns = {\"_\".join(col.split(\"_\")[:m[i]]) for i, col in enumerate(data.columns)}\n",
    "towns.remove(\"DATE\")\n",
    "towns.remove(\"MONTH\")\n",
    "towns.remove(\"ROMA\")\n",
    "towns.remove(\"MALMO\")\n",
    "labels = pd.read_csv(\"weather_data/weather_prediction_picnic_labels.csv\").replace({True: 1, False: 0})\n",
    "data = data.join(labels.set_index(\"DATE\"), on=\"DATE\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "id": "09b0aa98-32cc-4fcf-a019-fae4cf070de4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TOWN       is full\n",
      "DE_BILT      YES\n",
      "Index(['cloud_cover', 'wind_speed', 'wind_gust', 'humidity', 'pressure',\n",
      "       'global_radiation', 'precipitation', 'sunshine', 'temp_mean',\n",
      "       'temp_min', 'temp_max', 'picnic_weather'],\n",
      "      dtype='object')\n",
      "\n",
      "TOURS        NO\n",
      "Index(['wind_speed', 'humidity', 'pressure', 'global_radiation',\n",
      "       'precipitation', 'temp_mean', 'temp_min', 'temp_max', 'picnic_weather'],\n",
      "      dtype='object')\n",
      "\n",
      "LJUBLJANA    NO\n",
      "Index(['cloud_cover', 'wind_speed', 'humidity', 'pressure', 'global_radiation',\n",
      "       'precipitation', 'sunshine', 'temp_mean', 'temp_min', 'temp_max',\n",
      "       'picnic_weather'],\n",
      "      dtype='object')\n",
      "\n",
      "MAASTRICHT   YES\n",
      "Index(['cloud_cover', 'wind_speed', 'wind_gust', 'humidity', 'pressure',\n",
      "       'global_radiation', 'precipitation', 'sunshine', 'temp_mean',\n",
      "       'temp_min', 'temp_max', 'picnic_weather'],\n",
      "      dtype='object')\n",
      "\n",
      "MUENCHEN     YES\n",
      "Index(['cloud_cover', 'wind_speed', 'wind_gust', 'humidity', 'pressure',\n",
      "       'global_radiation', 'precipitation', 'sunshine', 'temp_mean',\n",
      "       'temp_min', 'temp_max', 'picnic_weather'],\n",
      "      dtype='object')\n",
      "\n",
      "PERPIGNAN    NO\n",
      "Index(['wind_speed', 'humidity', 'pressure', 'global_radiation',\n",
      "       'precipitation', 'temp_mean', 'temp_min', 'temp_max', 'picnic_weather'],\n",
      "      dtype='object')\n",
      "\n",
      "HEATHROW     NO\n",
      "Index(['cloud_cover', 'humidity', 'pressure', 'global_radiation',\n",
      "       'precipitation', 'sunshine', 'temp_mean', 'temp_min', 'temp_max',\n",
      "       'picnic_weather'],\n",
      "      dtype='object')\n",
      "\n",
      "BUDAPEST     NO\n",
      "Index(['cloud_cover', 'humidity', 'pressure', 'global_radiation',\n",
      "       'precipitation', 'sunshine', 'temp_mean', 'temp_max', 'picnic_weather'],\n",
      "      dtype='object')\n",
      "\n",
      "MONTELIMAR   NO\n",
      "Index(['wind_speed', 'humidity', 'pressure', 'global_radiation',\n",
      "       'precipitation', 'temp_mean', 'temp_min', 'temp_max', 'picnic_weather'],\n",
      "      dtype='object')\n",
      "\n",
      "DUSSELDORF   YES\n",
      "Index(['cloud_cover', 'wind_speed', 'wind_gust', 'humidity', 'pressure',\n",
      "       'global_radiation', 'precipitation', 'sunshine', 'temp_mean',\n",
      "       'temp_min', 'temp_max', 'picnic_weather'],\n",
      "      dtype='object')\n",
      "\n",
      "DRESDEN      NO\n",
      "Index(['cloud_cover', 'wind_speed', 'wind_gust', 'humidity',\n",
      "       'global_radiation', 'precipitation', 'sunshine', 'temp_mean',\n",
      "       'temp_min', 'temp_max', 'picnic_weather'],\n",
      "      dtype='object')\n",
      "\n",
      "STOCKHOLM    NO\n",
      "Index(['cloud_cover', 'pressure', 'precipitation', 'sunshine', 'temp_mean',\n",
      "       'temp_min', 'temp_max', 'picnic_weather'],\n",
      "      dtype='object')\n",
      "\n",
      "SONNBLICK    NO\n",
      "Index(['cloud_cover', 'humidity', 'global_radiation', 'precipitation',\n",
      "       'sunshine', 'temp_mean', 'temp_min', 'temp_max', 'picnic_weather'],\n",
      "      dtype='object')\n",
      "\n",
      "BASEL        NO\n",
      "Index(['cloud_cover', 'humidity', 'pressure', 'global_radiation',\n",
      "       'precipitation', 'sunshine', 'temp_mean', 'temp_min', 'temp_max',\n",
      "       'picnic_weather'],\n",
      "      dtype='object')\n",
      "\n",
      "KASSEL       NO\n",
      "Index(['wind_speed', 'wind_gust', 'humidity', 'pressure', 'global_radiation',\n",
      "       'precipitation', 'sunshine', 'temp_mean', 'temp_min', 'temp_max',\n",
      "       'picnic_weather'],\n",
      "      dtype='object')\n",
      "\n",
      "OSLO         YES\n",
      "Index(['cloud_cover', 'wind_speed', 'wind_gust', 'humidity', 'pressure',\n",
      "       'global_radiation', 'precipitation', 'sunshine', 'temp_mean',\n",
      "       'temp_min', 'temp_max', 'picnic_weather'],\n",
      "      dtype='object')\n",
      "\n"
     ]
    }
   ],
   "source": [
    "all_combined = None\n",
    "town_data = {}\n",
    "cols = {}\n",
    "full_towns = set()\n",
    "print(f\"{'TOWN':10} is full\")\n",
    "for t in towns:\n",
    "    temp = data.loc[:, data.columns.str.startswith(t)]\n",
    "    temp.columns = [col.strip(t+\"_\") for col in temp.columns]\n",
    "    town_data[t] = temp\n",
    "    if len(temp.columns) == 12:\n",
    "        full_towns.add(t)\n",
    "        print(f\"{t:12} YES\")\n",
    "        print(temp.columns)\n",
    "        print()\n",
    "        if all_combined is None:\n",
    "            all_combined = temp\n",
    "            cols = temp.columns\n",
    "        else:\n",
    "            all_combined = pd.concat([all_combined, temp])\n",
    "            cols = cols.intersection(temp.columns)\n",
    "    else:\n",
    "        print(f\"{t:12} NO\")\n",
    "        print(temp.columns)\n",
    "        print()\n",
    "all_full_combined = all_combined.reset_index().drop(\"index\", axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "id": "6eaf5c70-8c8d-434e-802b-b85c64dfa899",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_town_data(data_split, town, seed):\n",
    "    # Load and shuffle\n",
    "    tow = town_data[town]\n",
    "    tow = shuffle(tow,random_state=seed)\n",
    "    \n",
    "    n = tow.shape[0]\n",
    "    k = sum(data_split)\n",
    "    train_stop = int(n*data_split[0]/k)\n",
    "    test_stop = train_stop+int(n*data_split[1]/k)\n",
    "    \n",
    "    # Split data and label\n",
    "    data = tow.loc[:, tow.columns[:-1]]\n",
    "    labels = tow.loc[:, tow.columns[-1]]\n",
    "\n",
    "    # Split train and test\n",
    "    train_data = data.iloc[:train_stop, :]\n",
    "    test_data = data.iloc[train_stop:test_stop, :]\n",
    "    valid_data = data.iloc[test_stop:, :]\n",
    "    train_labels = labels.iloc[:train_stop]\n",
    "    test_labels = labels.iloc[train_stop:test_stop]\n",
    "    valid_labels = labels.iloc[test_stop:]\n",
    "\n",
    "    # Normalize\n",
    "    means = train_data.mean(axis=0)\n",
    "    var = train_data.var(axis=0)\n",
    "    train_data = (train_data-means)/(var**0.5)\n",
    "    test_data = (test_data-means)/(var**0.5)\n",
    "    valid_data = (valid_data-means)/(var**0.5)\n",
    "\n",
    "    return train_data, train_labels, test_data, test_labels, valid_data, valid_labels, means, var"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "9a4a6d13-bf48-4ab9-842f-3278d860f3e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_multiple_town_data(train_size, towns, seed, testing):\n",
    "    # Load and shuffle\n",
    "    tow = None\n",
    "    for  t in towns:\n",
    "        temp = town_data[t]\n",
    "        if tow is None:\n",
    "            tow = temp\n",
    "        else:\n",
    "            tow = pd.concat([tow, temp])\n",
    "            \n",
    "    tow = shuffle(tow,random_state=seed)\n",
    "    \n",
    "    # Split data and label\n",
    "    data = tow.loc[:, tow.columns[:-1]]\n",
    "    labels = tow.loc[:, tow.columns[-1]]\n",
    "\n",
    "    if testing:\n",
    "        # Split train and test\n",
    "        train_data = data.iloc[:train_size, :]\n",
    "        test_data = data.iloc[train_size:, :]\n",
    "        train_labels = labels.iloc[:train_size]\n",
    "        test_labels = labels.iloc[train_size:]\n",
    "\n",
    "        # Normalize\n",
    "        means = train_data.mean(axis=0)\n",
    "        var = train_data.var(axis=0)\n",
    "        train_data = (train_data-means)/(var**0.5)\n",
    "        test_data = (test_data-means)/(var**0.5)\n",
    "\n",
    "        return train_data, train_labels, test_data, test_labels, means, var\n",
    "    else:\n",
    "        # Normalize\n",
    "        means = data.mean(axis=0)\n",
    "        var = data.var(axis=0)\n",
    "        data = (data-means)/(var**0.5)\n",
    "\n",
    "        return data, labels, means, var"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95006437-1071-4a30-afa0-1cd9b1ce8d12",
   "metadata": {},
   "source": [
    "BASEL test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "id": "d080644b-e09f-471d-80cf-e8de7cacb98e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 286,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "va_l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "id": "43669906-3a0f-4048-9178-aa565fe94fac",
   "metadata": {},
   "outputs": [],
   "source": [
    "tr_d, tr_l, te_d, te_l, va_d, va_l, m, v = get_town_data([8,1,1], \"BASEL\", 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "id": "1e86f292-edc5-4ca6-a53e-9604c507fc90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23 0.8931506849315067\n"
     ]
    }
   ],
   "source": [
    "val = 11\n",
    "step = 4\n",
    "way = 1\n",
    "best_score = 0\n",
    "best_val = val\n",
    "tested = False\n",
    "\n",
    "while step > 0.02:\n",
    "    svc = svm.SVC(C=val, kernel='rbf', random_state=42)\n",
    "    svc.fit(tr_d, tr_l)\n",
    "    cross_score = np.mean(cross_val_score(svc, te_d, te_l, cv=5))\n",
    "    if cross_score > best_score:\n",
    "        best_score = cross_score\n",
    "        best_val = val \n",
    "        tested = False\n",
    "    elif not tested:\n",
    "        way *= -1\n",
    "        #step /= 2\n",
    "        tested = True\n",
    "    else:\n",
    "        step /= 2\n",
    "        tested = False\n",
    "    #print(val, cross_score)\n",
    "    val += step*way\n",
    "    \n",
    "\n",
    "print(best_val, best_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "id": "93152b3a-701b-4d1c-8569-bc675f1c5047",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23 0.9424657534246575\n"
     ]
    }
   ],
   "source": [
    "val = 11\n",
    "step = 4\n",
    "way = 1\n",
    "best_score = 0\n",
    "best_val = val\n",
    "tested = False\n",
    "\n",
    "while step > 0.02:\n",
    "    lin_svc = svm.LinearSVC(C=val, dual=\"auto\", random_state=42)\n",
    "    lin_svc.fit(tr_d, tr_l)\n",
    "    cross_score = np.mean(cross_val_score(lin_svc, te_d, te_l, cv=5))\n",
    "    if cross_score > best_score:\n",
    "        best_score = cross_score\n",
    "        best_val = val \n",
    "        tested = False\n",
    "    elif not tested:\n",
    "        way *= -1\n",
    "        #step /= 2\n",
    "        tested = True\n",
    "    else:\n",
    "        step /= 2\n",
    "        tested = False\n",
    "    #print(val, cross_score)\n",
    "    val += step*way\n",
    "    \n",
    "\n",
    "print(best_val, best_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "id": "2b0add5e-f499-411d-9def-e6f559f2bb6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1e-08 0.8931506849315068\n"
     ]
    }
   ],
   "source": [
    "val = 1\n",
    "step = 0.8\n",
    "way = 1\n",
    "best_score = 0\n",
    "best_val = val\n",
    "tested = False\n",
    "\n",
    "while step > 0.00002:\n",
    "    svc_with_sgd = linear_model.SGDClassifier(alpha=val, random_state=42, loss=\"hinge\")\n",
    "    svc_with_sgd.fit(tr_d, tr_l)\n",
    "    cross_score = np.mean(cross_val_score(svc_with_sgd, te_d, te_l, cv=5))\n",
    "    if cross_score > best_score:\n",
    "        best_score = cross_score\n",
    "        best_val = val \n",
    "        tested = False\n",
    "    elif not tested:\n",
    "        way *= -1\n",
    "        #step /= 2\n",
    "        tested = True\n",
    "    else:\n",
    "        step /= 2\n",
    "        tested = False\n",
    "    #print(val, cross_score)\n",
    "    val = max(0.00000001, val+step*way)\n",
    "    \n",
    "\n",
    "print(best_val, best_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "id": "a104f4ee-4793-4678-acad-1458991c38f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVC RBF: 0.9263235838578303\n",
      "SVC Lin: 0.9536097741577194\n",
      "SVC SGD: 0.8880414661236579\n"
     ]
    }
   ],
   "source": [
    "cross_score = np.mean(cross_val_score(svc, va_d, va_l, cv=5))\n",
    "print(f\"SVC RBF: {cross_score}\")\n",
    "cross_score = np.mean(cross_val_score(lin_svc, va_d, va_l, cv=5))\n",
    "print(f\"SVC Lin: {cross_score}\")\n",
    "cross_score = np.mean(cross_val_score(svc_with_sgd, va_d, va_l, cv=5))\n",
    "print(f\"SVC SGD: {cross_score}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "id": "7767f3ae-949e-4afd-870a-b321be5267cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-24 {color: black;}#sk-container-id-24 pre{padding: 0;}#sk-container-id-24 div.sk-toggleable {background-color: white;}#sk-container-id-24 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-24 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-24 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-24 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-24 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-24 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-24 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-24 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-24 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-24 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-24 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-24 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-24 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-24 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-24 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-24 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-24 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-24 div.sk-item {position: relative;z-index: 1;}#sk-container-id-24 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-24 div.sk-item::before, #sk-container-id-24 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-24 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-24 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-24 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-24 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-24 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-24 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-24 div.sk-label-container {text-align: center;}#sk-container-id-24 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-24 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-24\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestClassifier(max_depth=5, random_state=0)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-24\" type=\"checkbox\" checked><label for=\"sk-estimator-id-24\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier(max_depth=5, random_state=0)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "RandomForestClassifier(max_depth=5, random_state=0)"
      ]
     },
     "execution_count": 203,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = RandomForestClassifier(max_depth=5, random_state=0)\n",
    "clf.fit(tr_d, tr_l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "id": "decbb19d-8ffe-46f5-ac89-d95f9aa5af13",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9915090543259557"
      ]
     },
     "execution_count": 204,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "crossScore = np.mean(cross_val_score(clf, te_d, te_l, cv=5))\n",
    "crossScore"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2359dc74-1830-4a25-90c3-cfdd7cc5fd7e",
   "metadata": {},
   "source": [
    "Simple NN vs Tranfer learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "id": "62062d73-588c-40e3-9a31-873c0ff0b948",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TEST TOWN: MAASTRICHT\n"
     ]
    }
   ],
   "source": [
    "ft = full_towns.copy()\n",
    "tt = ft.pop()\n",
    "\n",
    "print(f\"TEST TOWN: {tt}\")\n",
    "\n",
    "main_tr_d, main_tr_l, _, _ = get_multiple_town_data(0, ft, 42, False)\n",
    "\n",
    "spe_tr_d, spe_tr_l, spe_te_d, spe_te_l, _, _, _, _ = get_town_data([9,1,0], tt, 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43c03dda-d06e-465f-bf75-dba7471279cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp_for_transfer = Sequential()\n",
    "mlp_for_transfer.add(Dense(12, activation='tanh', input_dim=main_tr_d.shape[1]))\n",
    "mlp_for_transfer.add(Dense(6, activation='tanh', input_dim=main_tr_d.shape[1]))\n",
    "mlp_for_transfer.add(Dense(2, activation='softmax'))\n",
    "\n",
    "mlp_for_transfer.compile(loss='binary_crossentropy', optimizer=keras.optimizers.SGD(learning_rate=0.4),  metrics=['accuracy'])\n",
    "\n",
    "history_for_transfer = mlp_for_transfer.fit(main_tr_d, keras.utils.to_categorical(main_tr_l), epochs=50, validation_split=0.1, verbose=False)\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(history_for_transfer.history['loss'], label='training loss')\n",
    "plt.plot(history_for_transfer.history['val_loss'], label='validation loss')\n",
    "plt.legend(loc='best')\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(history_for_transfer.history['accuracy'], label='train accuracy')\n",
    "plt.plot(history_for_transfer.history['val_accuracy'], label='validation accuracy')\n",
    "plt.legend(loc='best')\n",
    "plt.show()\n",
    "\n",
    "score = mlp_for_transfer.evaluate(spe_te_d, keras.utils.to_categorical(spe_te_l))\n",
    "print(\"\\n\\nloss: {} | train acc: {}\".format(score[0], score[1]))\n",
    "\n",
    "for i in range(len(mlp_for_transfer.layers)-1):\n",
    "    mlp_for_transfer.layers[i].trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc827d53-2475-4e05-9f2e-43b75863ebec",
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp_straightforward = Sequential()\n",
    "mlp_straightforward.add(Dense(12, activation='tanh', input_dim=spe_tr_d.shape[1]))\n",
    "mlp_straightforward.add(Dense(6, activation='tanh', input_dim=spe_tr_d.shape[1]))\n",
    "mlp_straightforward.add(Dense(2, activation='softmax'))\n",
    "\n",
    "mlp_straightforward.compile(loss='binary_crossentropy', optimizer=keras.optimizers.SGD(learning_rate=0.4),  metrics=['accuracy'])\n",
    "\n",
    "history_straightforward = mlp_straightforward.fit(spe_tr_d, keras.utils.to_categorical(spe_tr_l), epochs=50, validation_split=0.1, verbose=False)\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(history_straightforward.history['loss'], label='training loss')\n",
    "plt.plot(history_straightforward.history['val_loss'], label='validation loss')\n",
    "plt.legend(loc='best')\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(history_straightforward.history['accuracy'], label='train accuracy')\n",
    "plt.plot(history_straightforward.history['val_accuracy'], label='validation accuracy')\n",
    "plt.legend(loc='best')\n",
    "\n",
    "score = mlp_straightforward.evaluate(spe_te_d, keras.utils.to_categorical(spe_te_l))\n",
    "print(\"\\n\\nloss: {} | train acc: {}\".format(score[0], score[1]))\n",
    "\n",
    "history_transfer = mlp_for_transfer.fit(spe_tr_d, keras.utils.to_categorical(spe_tr_l), epochs=50, validation_split=0.1, verbose=False)\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(history_transfer.history['loss'], label='training loss')\n",
    "plt.plot(history_transfer.history['val_loss'], label='validation loss')\n",
    "plt.legend(loc='best')\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(history_transfer.history['accuracy'], label='train accuracy')\n",
    "plt.plot(history_transfer.history['val_accuracy'], label='validation accuracy')\n",
    "plt.legend(loc='best')\n",
    "plt.show()\n",
    "\n",
    "score = mlp_for_transfer.evaluate(spe_te_d, keras.utils.to_categorical(spe_te_l))\n",
    "print(\"\\n\\nloss: {} | train acc: {}\".format(score[0], score[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0804eb95-5791-4ed0-a354-7fc0ebfcb8bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "score = mlp_straightforward.evaluate(spe_te_d, keras.utils.to_categorical(spe_te_l))\n",
    "print(\"\\n\\nWithout transfering: loss: {} | train acc: {}\\n\".format(score[0], score[1]))\n",
    "\n",
    "score = mlp_for_transfer.evaluate(spe_te_d, keras.utils.to_categorical(spe_te_l))\n",
    "print(\"\\n\\n With transfering:   loss: {} | train acc: {}\".format(score[0], score[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f29dbf4-bf8f-4814-9f0d-6ff1d3d9ab95",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "projektStrojUc",
   "language": "python",
   "name": "projektstrojuc"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
